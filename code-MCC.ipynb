{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "########## Loading Necessary Libraries  ##########\n",
    "##################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "p = mp.Pool(mp.cpu_count())\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.linalg import inv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "########### Loading and Cleaning Data ############\n",
    "##################################################\n",
    "\n",
    "# # Load data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Extracting the target variable for final accuracy calculation\n",
    "y = data['diagnosis']\n",
    "\n",
    "##### Preprocessing the data #####\n",
    "X = data.drop(['id', 'diagnosis','Unnamed: 32'], axis=1)\n",
    "\n",
    "# Cleaning the data \n",
    "corr = X.corr()\n",
    "corr_t = corr.abs().unstack()\n",
    "corr_t = corr_t.sort_values(kind=\"quicksort\")\n",
    "col_to_drop = []\n",
    "for i in range(1, len(corr_t)):\n",
    "    if corr_t[i] > 0.9 and corr_t.index[i][0] != corr_t.index[i][1]:\n",
    "        col_to_drop.append([corr_t.index[i][0], corr_t.index[i][1]])\n",
    "# Calculate total correlation of each column in col_to_drop\n",
    "total_corrs = corr.abs().sum(axis=1).sort_values(ascending=False)\n",
    "droped_cols = []\n",
    "for i in col_to_drop:\n",
    "    if(i[0] in droped_cols or i[1] in droped_cols):\n",
    "        continue\n",
    "    elif total_corrs[i[0]] > total_corrs[i[1]]:\n",
    "        X.drop(i[1], axis=1, inplace=True)\n",
    "        droped_cols.append(i[1])\n",
    "    else:\n",
    "        X.drop(i[0], axis=1, inplace=True)\n",
    "        droped_cols.append(i[0])\n",
    "\n",
    "##### Cleaning and standardizing the data #####\n",
    "y = data['diagnosis']\n",
    "df_Y = pd.DataFrame(y)\n",
    "df_Y['diagnosis'] = df_Y['diagnosis'].apply(lambda x: 1 if x == 'M' else 2)\n",
    "y = df_Y\n",
    "\n",
    "max_correlation = 5\n",
    "corr = X.corr()\n",
    "# Choose the highest correlation columns\n",
    "highest_corr_col = corr.abs().sum(axis=1).sort_values(ascending=False).head(1)\n",
    "while(highest_corr_col[0] > max_correlation):\n",
    "    # Drop the highest correlation columns\n",
    "    X = X.drop(highest_corr_col.index, axis=1)\n",
    "    corr = X.corr()\n",
    "    highest_corr_col = corr.abs().sum(axis=1).sort_values(ascending=False).head(1)\n",
    "\n",
    "# convert y as df to a np.array\n",
    "np_y = np.array(y)\n",
    "\n",
    "# Get the length of y\n",
    "np_y_n = len(np_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithmMCC:\n",
    "    def __init__(self, population_size, max_generation, mutation_rate, crossover_rate, X, y):\n",
    "        self.population_size = population_size\n",
    "        self.max_generation = max_generation\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.entropies = {}\n",
    "        self.y = y\n",
    "        self.X = X.copy()\n",
    "        self.X.columns = [i+1 for i in range(len(self.X.columns))]\n",
    "        self.X[0] = 1\n",
    "        self.X = self.X.reindex(list(self.X.columns.sort_values()), axis=1)\n",
    "\n",
    "    def calculate_R2(self, df_Y):\n",
    "        XT = self.X.T.reset_index(drop=True)\n",
    "\n",
    "        b = inv(XT @ self.X) @ XT @ df_Y\n",
    "        bT = b.T.reset_index(drop=True)\n",
    "\n",
    "        temp1 = bT @ XT @ df_Y\n",
    "        SS = (temp1 - (1/len(self.X))*((self.X[0].T@df_Y)**2))\n",
    "        SS_error = (df_Y.T @ df_Y) - (temp1)\n",
    "        R2 = SS/ (SS + SS_error)\n",
    "\n",
    "        return SS[0][0], SS_error[0][0], R2[0][0]\n",
    "\n",
    "    def create_population(self):\n",
    "        # Unique values of y\n",
    "        values = self.y.diagnosis.unique()\n",
    "\n",
    "        # Create a list to store the population\n",
    "        population = pd.DataFrame(columns=['individual'])\n",
    "\n",
    "        # A for loop to create the population\n",
    "        for i in range(self.population_size):\n",
    "            # Create a random individual\n",
    "            individual = np.random.choice(values, size=len(self.y))\n",
    "            # Append the individual to the population\n",
    "            population = pd.concat([population, pd.DataFrame([{ 'individual': individual }])], ignore_index=True)\n",
    "\n",
    "        # Return the population\n",
    "        return population\n",
    "\n",
    "    def calculate_R2_score_apply(self, individual):\n",
    "        # Calculate the R2 Score of the individual\n",
    "        _, _, r2_score = self.calculate_R2(pd.DataFrame(individual))\n",
    "\n",
    "        print(\"r2_score : \", r2_score)\n",
    "\n",
    "        return r2_score\n",
    "\n",
    "    def calculate_fitness(self, population):\n",
    "        # Create a list to store the fitness\n",
    "        # population['fitness'] = population['individual'].apply(self.calculate_R2_score_apply)\n",
    "        population['fitness'] = p.map(self.calculate_R2_score_apply, population['individual'])\n",
    "        \n",
    "        # Return the fitness\n",
    "        return population\n",
    "\n",
    "    def select_parents(self, population):\n",
    "        # Select the parents\n",
    "        parents = np.random.choice(len(population), size=2, replace=False, p=probability)\n",
    "        \n",
    "        # Return the parents\n",
    "        return population['individual'][parents[0]], population['individual'][parents[1]]\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        # Create a random number for the crossover\n",
    "        crossover = np.random.random()\n",
    "\n",
    "        # Check if the crossover is less than the crossover rate\n",
    "        if crossover < self.crossover_rate:\n",
    "            # Create a random number for the crossover point\n",
    "            crossover_point = np.random.randint(0, len(parent1))\n",
    "\n",
    "            temp_parent1 = parent1\n",
    "            temp_parent2 = parent2\n",
    "\n",
    "            # Create a child 1\n",
    "            child1 = np.concatenate((temp_parent1[:crossover_point], temp_parent2[crossover_point:]))\n",
    "            # Create a child 2\n",
    "            child2 = np.concatenate((temp_parent2[:crossover_point], temp_parent1[crossover_point:]))\n",
    "\n",
    "            # Return the children\n",
    "            return child1, child2\n",
    "\n",
    "        # Return the parents\n",
    "        return parent1, parent2\n",
    "\n",
    "    def mutation(self, child):\n",
    "        # Create a random number for the mutation\n",
    "        mutation = np.random.random()\n",
    "\n",
    "        # Check if the mutation is less than the mutation rate\n",
    "        if mutation < self.mutation_rate:\n",
    "            # Create a random number for the mutation point\n",
    "            mutation_point = np.random.randint(0, len(child))\n",
    "\n",
    "            temp_child = child\n",
    "\n",
    "            # Create a list of unique values\n",
    "            unique_values = np.unique(temp_child)\n",
    "            # Remove current value from unique values\n",
    "            unique_values = np.delete(unique_values, np.where(unique_values == temp_child[mutation_point]))\n",
    "            \n",
    "            temp_child[mutation_point] = np.random.choice(unique_values)\n",
    "\n",
    "            # Return the child\n",
    "            return temp_child\n",
    "\n",
    "        # Return the child\n",
    "        return child\n",
    "\n",
    "    def select_parent_individually(self, population):\n",
    "        # Select the parent\n",
    "        parent = np.random.choice(len(population), size=1, replace=False, p=population['probability'])\n",
    "        \n",
    "        # Return the parents\n",
    "        return population['individual'][parent[0]]\n",
    "\n",
    "    def run_genetic_algorithm(self):\n",
    "        ##### Running the genetic algorithm #####\n",
    "\n",
    "        # Create initial population\n",
    "        population = self.create_population()\n",
    "        # Creating fields to store all time best and its fitness\n",
    "        all_time_best = []\n",
    "        all_time_best_fitness = 0\n",
    "        all_time_database = pd.DataFrame()\n",
    "\n",
    "        # Create a for loop to run the genetic algorithm\n",
    "        for i in range(0, self.max_generation):\n",
    "            print(\"Generation \" + str(i+1) + \" ...   \", end=\"\\r\")\n",
    "\n",
    "            # Calculate the fitness of the population\n",
    "            population = self.calculate_fitness(population)\n",
    "\n",
    "            # Check if the fitness of the population is greater than the all time best fitness\n",
    "            max_index = population['fitness'].idxmax()\n",
    "            if population['fitness'][max_index] > all_time_best_fitness:\n",
    "                all_time_best_fitness = population['fitness'][max_index]\n",
    "                all_time_best = population['individual'][max_index]\n",
    "\n",
    "            # Add population and fitness to all_time_database\n",
    "            all_time_database = pd.concat([all_time_database, population], ignore_index=True)\n",
    "\n",
    "            population['probability'] = population['fitness'] / sum(population['fitness'])\n",
    "            \n",
    "            # Create a list to store the new population\n",
    "            # new_population = pd.DataFrame(columns=['individual'])\n",
    "\n",
    "            new_population = pd.DataFrame(columns=['individual'])\n",
    "            new_population['individual'] = pd.Series([self.select_parent_individually(population) for i in range(0, self.population_size)])\n",
    "\n",
    "            # Apply Crossover\n",
    "            for j in range(0, int(self.population_size/2)):\n",
    "                # Crossover\n",
    "                child1, child2 = self.crossover(new_population['individual'][j*2], new_population['individual'][j*2+1])\n",
    "                # Add child1 and child2 to new_population\n",
    "                new_population['individual'][j*2] = child1\n",
    "                new_population['individual'][j*2+1] = child2\n",
    "\n",
    "            # Apply Mutation\n",
    "            # new_population['individual'] = new_population['individual'].apply(self.mutation)\n",
    "            new_population['individual'] = p.map(self.mutation, new_population['individual'])\n",
    "\n",
    "            population = new_population\n",
    "\n",
    "        # Return the all time best and its fitness\n",
    "        return all_time_best, all_time_best_fitness, all_time_database\n",
    "\n",
    "##############################################\n",
    "##### Functions for Calculating Accuracy #####\n",
    "##############################################\n",
    "\n",
    "def calculate_accuracy(predicted_y):\n",
    "    # Create a for loop to calculate accuracy\n",
    "    accuracy = 0\n",
    "    for i in range(0, np_y_n):\n",
    "        if np_y[i] == predicted_y[i]:\n",
    "            accuracy = accuracy + 1\n",
    "\n",
    "    # Return accuracy\n",
    "    return accuracy/np_y_n\n",
    "\n",
    "##############################################\n",
    "########### Defining Run Function ############\n",
    "##############################################\n",
    "\n",
    "#Function to run the genetic algorithm with multiple configurations\n",
    "def multi_run(run_configuration):\n",
    "    all_individuals = pd.DataFrame(columns=['individual', 'fitness', 'accuracy', 'run'])\n",
    "\n",
    "    # Create a list to store the accuracy\n",
    "    results = []\n",
    "    print(\"Running the genetic algorithm, for \" + str(len(run_configuration)) + \" runs ...\")\n",
    "    # A for loop to run the genetic algorithm multiple times\n",
    "    for i in range(0, len(run_configuration)):\n",
    "        print(\"Run \" + str(i+1) + \" ...          \")\n",
    "\n",
    "        # Set start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run the genetic algorithm\n",
    "        gen_algo = GeneticAlgorithmMCC(run_configuration[i]['population_size'], run_configuration[i]['max_generation'], run_configuration[i]['mutation_rate'], run_configuration[i]['crossover_rate'], X, y)\n",
    "        all_time_best, all_time_best_fitness, all_time_database = gen_algo.run_genetic_algorithm()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        accuracy = calculate_accuracy(all_time_best)\n",
    "\n",
    "        mid_time = time.time()\n",
    "\n",
    "        # Go through the all_time_database to get all the individuals, if the individual is not in all_individuals, add it to all_individuals with its fitness and calculated accuracy)\n",
    "        # all_time_database['accuracy'] = all_time_database['individual'].apply(calculate_accuracy)\n",
    "        all_time_database['accuracy'] = p.map(calculate_accuracy, all_time_database['individual'])\n",
    "        all_time_database['run'] = i\n",
    "        all_individuals = pd.concat([all_individuals, all_time_database], ignore_index=True)\n",
    "\n",
    "        # Set end time\n",
    "        first_half_time = mid_time - start_time\n",
    "        second_half_time = time.time() - mid_time\n",
    "\n",
    "        # update the results, append the configuration and the accuracy, destructure the configuration\n",
    "        results.append({\n",
    "            **run_configuration[i],\n",
    "            'accuracy': accuracy,\n",
    "            'all_time_best': all_time_best,\n",
    "            'all_time_best_fitness': all_time_best_fitness,\n",
    "            'first_half_time': first_half_time,\n",
    "            'second_half_time': second_half_time\n",
    "        })\n",
    "    print(\"Done!                              \")\n",
    "    # Return the accuracy\n",
    "    return results, all_individuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VERY IMPORTANT NOTE\n",
    "\n",
    "Please note that due to an issue with multiprocessing library, the next code block should be ran twice and stop it manually to work for the rest of the runs. I have tried some of the work around (like moving the functions of Pool.map to an external file), but because of some data access and other issues (like being unable to pass other parameter's to the function) I was unable to make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "################## Run the code ##################\n",
    "##################################################\n",
    "\n",
    "run_configuration = [\n",
    "    {\n",
    "        'population_size': 300,\n",
    "        'max_generation': 2000,\n",
    "        'mutation_rate': 0.2,\n",
    "        'crossover_rate': 0.8\n",
    "    },\n",
    "    {\n",
    "        'population_size': 300,\n",
    "        'max_generation': 2000,\n",
    "        'mutation_rate': 0.3,\n",
    "        'crossover_rate': 0.8\n",
    "    },\n",
    "    {\n",
    "        'population_size': 300,\n",
    "        'max_generation': 2000,\n",
    "        'mutation_rate': 0.4,\n",
    "        'crossover_rate': 0.8\n",
    "    },\n",
    "]\n",
    "\n",
    "results, all_individuals = multi_run(run_configuration)\n",
    "\n",
    "# Set the test time end\n",
    "test_time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "############ Processing results data #############\n",
    "##################################################\n",
    "\n",
    "# Export run_configuration to a csv file\n",
    "run_configuration_df = pd.DataFrame(run_configuration)\n",
    "run_configuration_df.to_csv('MCC-run_configuration-' + time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime(test_time_end)) + '.csv', index=False)\n",
    "\n",
    "# Create a chart to show the results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.drop(['all_time_best'], axis=1)\n",
    "results_df = results_df.sort_values(by=['accuracy'], ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "\n",
    "# Export the results to a csv file\n",
    "results_df.to_csv('MCC-results-' + time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime(test_time_end)) + '.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "########### Plotting all_individuals #############\n",
    "##################################################\n",
    "\n",
    "# Create a chart to show all_individuals with their fitness and accuracy as axes\n",
    "all_individuals = all_individuals.reset_index(drop=True)\n",
    "\n",
    "# Export the all_individuals to a csv file\n",
    "all_individuals.to_csv('MCC-all_individuals_list-' + time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime(test_time_end)) + '.csv', index=False)\n",
    "\n",
    "# Print total number of unique individuals\n",
    "print(\"Total number of unique individuals: \" + str(len(all_individuals)))\n",
    "\n",
    "# Plot all_individuals and fit a line, colorized by number of run\n",
    "\n",
    "fig, axs = plt.subplots(len(run_configuration) + 1, 1, figsize=(10, 20))\n",
    "\n",
    "for i in range(len(run_configuration)):\n",
    "    axs[i].scatter(all_individuals[all_individuals['run'] == i]['fitness'], all_individuals[all_individuals['run'] == i]['accuracy'], s=1)\n",
    "    z = np.polyfit(all_individuals[all_individuals['run'] == i]['fitness'], all_individuals[all_individuals['run'] == i]['accuracy'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axs[i].plot(all_individuals[all_individuals['run'] == i]['fitness'], p(all_individuals[all_individuals['run'] == i]['fitness']), \"r--\")\n",
    "    axs[i].set_xlabel('Fitness')\n",
    "    axs[i].set_ylabel('Accuracy')\n",
    "    axs[i].set_title('Run ' + str(i+1))\n",
    "\n",
    "# Plotting all runs\n",
    "axs[len(run_configuration)].scatter(all_individuals['fitness'], all_individuals['accuracy'], c=all_individuals['run'], s=1)\n",
    "z = np.polyfit(all_individuals['fitness'], all_individuals['accuracy'], 1)\n",
    "p = np.poly1d(z)\n",
    "axs[len(run_configuration)].plot(all_individuals['fitness'], p(all_individuals['fitness']), \"r--\")\n",
    "axs[len(run_configuration)].set_xlabel('Fitness')\n",
    "axs[len(run_configuration)].set_ylabel('Accuracy')\n",
    "axs[len(run_configuration)].set_title('All Runs')\n",
    "\n",
    "# Export the plot to a png file, name: all_individuals-DATE-TIME.png\n",
    "plt.savefig('MCC-all_individuals_chart-' + time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime(test_time_end)) + '.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a2c4b191d1ae843dde5cb5f4d1f62fa892f6b79b0f9392a84691e890e33c5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
